{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatDog-V4(ResNet50)-WNB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oWRkcK_DSUbv",
        "EVBnV--PfgFR",
        "KPsChc1HfR1g",
        "V4SidOu22W9T"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimEverest/Deeplearning_Colab/blob/master/CatDog_V4(ResNet50)_WNB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7HS9c8MCXx",
        "colab_type": "text"
      },
      "source": [
        "#For Tensorboard ext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_NzvnlSIK-r",
        "colab_type": "code",
        "outputId": "0e928f8d-c42d-489c-f5a6-6742e234f366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  print(\"TF2 Not working\")\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezHskie4MJxD",
        "colab_type": "text"
      },
      "source": [
        "#import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn-6c02VmqiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6172304f-db64-41bb-bc0a-519e362d8a86"
      },
      "source": [
        "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n",
        "# This will require you doing a lot of data preprocessing because\n",
        "# the dataset isn't split into training and validation for you\n",
        "# This code block has all the required inputs\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "import requests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ57DMLp_Tc_",
        "colab_type": "code",
        "outputId": "d4309103-1966-4193-8778-7a2c092546c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LMyh-Ljn0sp",
        "colab_type": "text"
      },
      "source": [
        "# W and B\n",
        "[Quick Start](https://docs.wandb.com/quickstart)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi84TgqznBR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install wandb\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "#bdc4ecd13b42f56d349429a38d217e9ed358809a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAU9hGEnQqL",
        "colab_type": "code",
        "outputId": "ac2d1899-79a0-4f18-ef76-67b8062064e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: bdc4ecd13b42f56d349429a38d217e9ed358809a\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLWTUh8UnshT",
        "colab_type": "code",
        "outputId": "d09bbaea-dd25-4ca3-cb48-f2d4d1dd2f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# name — A display name for this run\n",
        "# notes — A multiline string description associated with the run\n",
        "# config — a dictionary-like object to set as initial config\n",
        "# project — the name of the project to which this run will belong\n",
        "# tags — a list of strings to associate with this run as tags\n",
        "# dir — the path to a directory where artifacts will be written (default: ./wandb)\n",
        "# entity — the team posting this run (default: your username or your default team)\n",
        "# job_type — the type of job you are logging, e.g. eval, worker, ps (default: training)\n",
        "# group — a string by which to group other runs; see Grouping\n",
        "# reinit — whether to allow multiple calls to wandb.init in the same process (default: False)\n",
        "# id — A unique id for this run primarily used for resuming; see Resuming, must be globally unique within a project\n",
        "# resume — if set to True, the run auto resumes; can also be a unique string for manual resuming; see Resuming (default: False)\n",
        "# anonymous — can be \"allow\", \"never\", or \"must\". This enables or explicitly disables anonymous logging. (default: None)\n",
        "# force — whether to force a user to be logged into wandb when running a script (default: False)\n",
        "# magic — (bool, dict, or str, optional): magic configuration as bool, dict, json string, yaml filename. If set to True will attempt to auto-instrument your script. (default: None)\n",
        "# sync_tensorboard — A boolean indicating whether or not copy all tensorboard logs wandb; see Tensorboard (default: False)\n",
        "# monitor_gym — A boolean indicating whether or not to log videos generated by OpenAI Gym; see Ray Tune (default: False)\n",
        "# allow_val_change — whether to allow wandb.config values to change, by default we throw an exception if config values are overwritten. (default: False)\n",
        "\n",
        "wandb.init( name = \"CatDog-V4(ResNet50)_2\" , project=\"CAT_DOG\")\n",
        "config = wandb.config\n",
        "\n",
        "config.batch_size = 32\n",
        "config.epochs=5"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/tianwai263/CAT_DOG\" target=\"_blank\">https://app.wandb.ai/tianwai263/CAT_DOG</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/tianwai263/CAT_DOG/runs/t49nxzzi\" target=\"_blank\">https://app.wandb.ai/tianwai263/CAT_DOG/runs/t49nxzzi</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1kvQp-ZMMrw",
        "colab_type": "text"
      },
      "source": [
        "# Download/Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZb1G0L8SghS",
        "colab_type": "code",
        "outputId": "f70b3551-29c3-421e-c4b5-9492ab184627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SpMfKCBSVV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# don't have to exec each time...\n",
        "\n",
        "\n",
        "\n",
        "def Download_file_2_Drive(url,path):\n",
        "  file_url = url #\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "  file_name = file_url.split(\"/\")[-1]\n",
        "  r = requests.get(file_url, stream = True)  \n",
        "\n",
        "  dest_path = path #\"/content/drive/Shared drives/Share/Data/\"\n",
        "  os.makedirs(dest_path, exist_ok=True)\n",
        "  dest_path = os.path.join(dest_path,file_name)\n",
        "  with open(dest_path, \"wb\") as file:  \n",
        "      for block in r.iter_content(chunk_size = 1024): \n",
        "          if block:  \n",
        "              file.write(block)  \n",
        "\n",
        "Download_file_2_Drive(\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\", \"/content/drive/Shared drives/Share/Data/\")\n",
        "\n",
        "# Download_file_2_Drive(\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\", \"/content/drive/My Drive/Data/\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8l-O6ZZBztc",
        "colab_type": "code",
        "outputId": "339faadb-8d28-4ff7-812e-a3659b843c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 15 05:14:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZzwpkKTahh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/Shared drives/Share/Data/kagglecatsanddogs_3367a.zip\" \"/tmp/cats-and-dogs1.zip\"\n",
        "# !cp \"/content/drive/My Drive/Data/kagglecatsanddogs_3367a.zip\" \"/tmp/cats-and-dogs1.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sd9dQWa23aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Deprecated) Download to colab runtime tmp folder \n",
        "\n",
        "# If the URL doesn't work,   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# !wget --no-check-certificate \\\n",
        "#     \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "#     -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRUpA9TjcLMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_zip = '/tmp/cats-and-dogs1.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzLOAHfH-UD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip to My Drive (Gdrive)\n",
        "\n",
        "# local_zip = '/content/drive/My Drive/Data/kagglecatsanddogs_3367a.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/content/drive/My Drive/Data/')\n",
        "# zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi3yD62a6X3S",
        "colab_type": "code",
        "outputId": "18836fcf-5ff1-41f1-b080-2e65fd427942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
        "\n",
        "# Expected Output:\n",
        "# 12501\n",
        "# 12501"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QkLjxpmyK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use os.mkdir to create your directories\n",
        "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
        "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
        "try:\n",
        "    #YOUR CODE GOES HERE\n",
        "    os.mkdir(\"/tmp/cats-v-dogs\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/cats\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/dogs\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing/cats\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing/dogs\")\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om7ta6BNnLLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSODo0f9LaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a python function called split_data which takes\n",
        "# a SOURCE directory containing the files\n",
        "# a TRAINING directory that a portion of the files will be copied to\n",
        "# a TESTING directory that a portion of the files will be copie to\n",
        "# a SPLIT SIZE to determine the portion\n",
        "# The files should also be randomized, so that the training set is a random\n",
        "# X% of the files, and the test set is the remaining files\n",
        "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
        "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
        "# and 10% of the images will be copied to the TESTING dir\n",
        "# Also -- All images should be checked, and if they have a zero file length,\n",
        "# they will not be copied over\n",
        "#\n",
        "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
        "# os.path.getsize(PATH) gives you the size of the file\n",
        "# copyfile(source, destination) copies a file from source to destination\n",
        "# random.sample(list, len(list)) shuffles a list\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "# YOUR CODE STARTS HERE\n",
        "  files=os.listdir(SOURCE)\n",
        "  flen= len(files)\n",
        "  trainLen= int(flen * SPLIT_SIZE)\n",
        "  rFiles=random.sample(files,len(files))\n",
        "  trains=rFiles[:trainLen]\n",
        "  tests= rFiles[trainLen:]\n",
        "  for trF in trains:\n",
        "    if(os.path.getsize(os.path.join(SOURCE,trF))>0):\n",
        "      copyfile(os.path.join( SOURCE,trF),os.path.join( TRAINING,trF) )\n",
        "  for teF in tests:\n",
        "    if(os.path.getsize(os.path.join( SOURCE,teF))>0):\n",
        "      copyfile(os.path.join( SOURCE,teF), os.path.join( TESTING,teF) )\n",
        "\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luthalB76ufC",
        "colab_type": "code",
        "outputId": "e360da8e-b1a2-43fd-99b4-ddebeaf5ac74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11249\n",
            "11249\n",
            "1251\n",
            "1251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmD-Y9NMZ27",
        "colab_type": "text"
      },
      "source": [
        "# Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRG7n-EYMDoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 3e-3\n",
        "DECAY = 0.4\n",
        "targetSize = (150,150)\n",
        "Epochs = 50\n",
        "input_data_shape = (150, 150, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0NWSoyc7CX",
        "colab_type": "code",
        "outputId": "d038c070-3c53-446d-9643-ef6a8558be4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LR"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNLycMSGfnhb",
        "colab_type": "text"
      },
      "source": [
        "#ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqqfFSlGTk2V",
        "colab_type": "text"
      },
      "source": [
        "A simple identity block of ResNet:\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FFOPEKHyXxVhSdw3soFIWYjnkq6dDVX7\" style=\"width:650px;height:150px;\">\n",
        "\n",
        "\n",
        "A slightly **more powerful** version of this identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers. It looks like this:\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-_vkZz0uOcyYQcWqaBgI_i2yeK-P-mom\" style=\"width:650px;height:150px;\"/>\n",
        "\n",
        "\n",
        "`1ST component of main path:`\n",
        "\n",
        "The first CONV2D has  `F1`  filters of shape `(1,1)` and a stride of (1,1). Its padding is `\"valid\"` and its name should be conv_name_base + '2a'. Use 0 as the seed for the random initialization.\n",
        "The first BatchNorm is normalizing the 'channels' axis. Its name should be bn_name_base + '2a'.\n",
        "Then apply the ReLU activation function. This has no name and no hyperparameters.\n",
        "\n",
        "\n",
        "`2ND component of main path:`\n",
        "\n",
        "The second CONV2D has  `F2`  filters of shape  `(f,f)`  and a stride of (1,1). Its padding is `\"same\"` and its name should be conv_name_base + '2b'. Use 0 as the seed for the random initialization.\n",
        "The second BatchNorm is normalizing the 'channels' axis. Its name should be bn_name_base + '2b'.\n",
        "Then apply the ReLU activation function. This has no name and no hyperparameters.\n",
        "\n",
        "\n",
        "`3RD component of main path:`\n",
        "\n",
        "The third CONV2D has  `F3`  filters of shape `(1,1)` and a stride of (1,1). Its padding is `\"valid\"` and its name should be conv_name_base + '2c'. Use 0 as the seed for the random initialization.\n",
        "The third BatchNorm is normalizing the 'channels' axis. Its name should be bn_name_base + '2c'.\n",
        "Note that there is no ReLU activation function in this component.\n",
        "\n",
        "`Final step:`\n",
        "\n",
        "The X_shortcut and the output from the 3rd layer X are added together.\n",
        "Hint: The syntax will look something like Add()([var1,var2])\n",
        "Then apply the ReLU activation function. This has no name and no hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MqVYtK2CzZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "Arguments:\n",
        "X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "stage -- integer, used to name the layers, depending on their position in the network\n",
        "block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "Returns:\n",
        "X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "\"\"\"\n",
        "def identity_block(X, f, filters, stage, block ):\n",
        "  conv_name_base=\"RES_CONV_\" + str(stage) + \"_\" + str(block)\n",
        "  bn_name_base=\"RES_BN_\" + str(stage) + \"_\" + str(block)\n",
        "  X_Short = X\n",
        "  F1,F2,F3 = filters\n",
        "  #1st\n",
        "  x = layers.Conv2D( F1, (1,1), padding='valid',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2a')(X)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "  #2nd\n",
        "  x = layers.Conv2D( F2, (f,f), padding='same',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2b')(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "  #3rd\n",
        "  x = layers.Conv2D( F3, (1,1), padding='valid',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2c')(X)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        " \n",
        "\n",
        "  x = layers.Add()([x,X_Short])\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOEL_akbJmOC",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 - The convolutional block\n",
        "\n",
        "The ResNet \"convolutional block\" is the second block type. \n",
        "\n",
        "You can use this type of block `when the input and output dimensions don't match up`. \n",
        "\n",
        "The difference with the identity block is that there is a CONV2D layer in the shortcut path: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=13z57SPRfNMooBdV_NZuWGLiqfbWQo8dH\" style=\"width:650px;height:150px;\">\n",
        "<caption><center> <u> <font color='purple'> **Figure 4** </u><font color='purple'>  : **Convolutional block** </center></caption>\n",
        "\n",
        "* The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.) \n",
        "* For example, to reduce the activation dimensions's height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2. \n",
        "* The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step. \n",
        "\n",
        "The details of the convolutional block are as follows. \n",
        "\n",
        "First component of main path:\n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be `conv_name_base + '2a'`. Use 0 as the `glorot_uniform` seed.\n",
        "- The first BatchNorm is normalizing the 'channels' axis.  Its name should be `bn_name_base + '2a'`.\n",
        "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
        "\n",
        "Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\" and it's name should be `conv_name_base + '2b'`.  Use 0 as the `glorot_uniform` seed.\n",
        "- The second BatchNorm is normalizing the 'channels' axis.  Its name should be `bn_name_base + '2b'`.\n",
        "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
        "\n",
        "Third component of main path:\n",
        "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\" and it's name should be `conv_name_base + '2c'`.  Use 0 as the `glorot_uniform` seed.\n",
        "- The third BatchNorm is normalizing the 'channels' axis.  Its name should be `bn_name_base + '2c'`. Note that there is no ReLU activation function in this component. \n",
        "\n",
        "Shortcut path:\n",
        "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be `conv_name_base + '1'`.  Use 0 as the `glorot_uniform` seed.\n",
        "- The BatchNorm is normalizing the 'channels' axis.  Its name should be `bn_name_base + '1'`. \n",
        "\n",
        "Final step: \n",
        "- The shortcut and the main path values are added together.\n",
        "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
        "    \n",
        "**Exercise**: Implement the convolutional block. We have implemented the first component of the main path; you should implement the rest. As before, always use 0 as the seed for the random initialization, to ensure consistency with our grader.\n",
        "- [Conv2D](https://keras.io/layers/convolutional/#conv2d)\n",
        "- [BatchNormalization](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
        "- For the activation, use:  `Activation('relu')(X)`\n",
        "- [Add](https://keras.io/layers/merge/#add)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1nXB7zDKKhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # # Stage 1\n",
        "    # X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    # X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    # X = Activation('relu')(X)\n",
        "    # X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # # Stage 2\n",
        "    # X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    # X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    # X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey-DAMycIt2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "Arguments:\n",
        "X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "stage -- integer, used to name the layers, depending on their position in the network\n",
        "block -- string/character, used to name the layers, depending on their position in the network\n",
        "s -- Integer, specifying the stride to be used\n",
        "\n",
        "Returns:\n",
        "X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "\"\"\"\n",
        "def convolutional_block(X, f, filters,stage,block, s):\n",
        "  conv_name_base = \"Res_Conv_\" + str(stage) + block + '_branch'\n",
        "  bn_name_base = \"BN_\" + str(stage) + block + '_branch'\n",
        "  F1,F2,F3 = filters\n",
        "  X_short = X\n",
        "\n",
        "  #1st\n",
        "  # print(\"X       SHAPE       : \" , X.shape)\n",
        "  x = layers.Conv2D( F1, (1,1),strides=(s,s), padding='valid',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2a')(X)\n",
        "  # print(\"strides             : \" , (s,s))\n",
        "  # print(\"X2      SHAPE(AFTER): \" , x.shape)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "  #2nd\n",
        "  x = layers.Conv2D( F2, (f,f), strides=(1,1),padding='same',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2b')(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  # print(\"X3      SHAPE(AFTER): \" , x.shape)\n",
        "  #3rd\n",
        "  x = layers.Conv2D( F3, (1,1), strides=(1,1),padding='valid',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '2c')(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "\n",
        "  # print(\"X4      SHAPE(AFTER): \" , x.shape)\n",
        "  #Shortcut\n",
        "  # print(\"X_short SHAPE(BEFOR): \" , X_short.shape)\n",
        "  X_short =layers.Conv2D( F3, (1,1),strides=(s,s), padding='valid',activation=None, kernel_initializer=glorot_uniform(seed=0), name = conv_name_base + '_st')(X_short)\n",
        "  X_short = layers.BatchNormalization(name=bn_name_base + '_st')(X_short)\n",
        "\n",
        "  # print(\"X_short SHAPE(AFTER): \" , X_short.shape)\n",
        "  # print(\"X5       SHAPE       : \" , x.shape)\n",
        "  # print(\"strides             : \" , (s,s))\n",
        "  # print(\"F3                  : \" , F3)\n",
        "  # print(\"----------------------------------\")\n",
        "  x = layers.Add()([x,X_short])\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpQ6AU54S3Jj",
        "colab_type": "text"
      },
      "source": [
        "3 - Building your first ResNet model (50 layers)\n",
        "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
        "\n",
        "![alt text](//github.com/priya-dwivedi/Deep-Learning/raw/090a6ff1f3236e6c216db6743af74f1728669e46/resnet_keras/images/resnet_kiank.png)\n",
        "\n",
        "The details of this ResNet-50 model are:\n",
        "\n",
        "Zero-padding pads the input with a pad of (3,3)\n",
        "Stage 1:\n",
        "The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n",
        "BatchNorm is applied to the channels axis of the input.\n",
        "MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "Stage 2:\n",
        "The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\".\n",
        "The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "Stage 3:\n",
        "The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
        "Stage 4:\n",
        "The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
        "Stage 5:\n",
        "The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "The 2 identity blocks use three set of filters of size [512, 512, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
        "The flatten doesn't have any hyperparameters or name.\n",
        "The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be 'fc' + str(classes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-kfAJx_TGs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_size=(150,150,3),classes=2):\n",
        "  \"\"\"\n",
        "  Implementation of the popular ResNet50 the following architecture:\n",
        "  CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "  -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "  Arguments:\n",
        "  input_shape -- shape of the images of the dataset\n",
        "  classes -- integer, number of classes\n",
        "\n",
        "  Returns:\n",
        "  model -- a Model() instance in Keras\n",
        "  \"\"\"\n",
        "  X_INPUT = layers.Input(input_size)\n",
        "  X = layers.ZeroPadding2D(padding=(3,3))(X_INPUT)\n",
        "  #1st Stage\n",
        "  X = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X_INPUT)\n",
        "  X = layers.BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "  #2nd Stage:\n",
        "  X = convolutional_block(X, 3, [64,64,256],2,\"a\", s=1)\n",
        "  X = identity_block(X, 3, [64,64,256], 2, \"b\" )\n",
        "  X = identity_block(X, 3, [64,64,256], 2, \"c\" )\n",
        "\n",
        "  #3rd Stage:\n",
        "  X = convolutional_block(X, 3, [128,128,512],3,\"a\", s=2)\n",
        "  X = identity_block(X, 3, [128,128,512], 3, \"b\" )\n",
        "  X = identity_block(X, 3, [128,128,512], 3, \"c\" )\n",
        "  X = identity_block(X, 3, [128,128,512], 3, \"d\" )\n",
        "\n",
        "\n",
        "  #4th Stage:\n",
        "  X = convolutional_block(X, 3, [256,256,1024],4,\"a\", s=2)\n",
        "  X = identity_block(X, 3, [256,256,1024], 4, \"b\" )\n",
        "  X = identity_block(X, 3, [256,256,1024], 4, \"c\" )\n",
        "  X = identity_block(X, 3, [256,256,1024], 4, \"d\" )\n",
        "  X = identity_block(X, 3, [256,256,1024], 4, \"e\" )\n",
        "  X = identity_block(X, 3, [256,256,1024], 4, \"f\" )\n",
        "\n",
        "\n",
        "  #5th Stage:\n",
        "  X = convolutional_block(X, 3, [512,512,2048],5,\"a\", s=2)\n",
        "  X = identity_block(X, 3, [512,512,2048], 5, \"b\" )\n",
        "  X = identity_block(X, 3, [512,512,2048], 5, \"c\" )\n",
        "\n",
        "  # POOLING\n",
        "  X = layers.AveragePooling2D(name = 'avg_pooling')(X)\n",
        "  X = layers.Flatten()(X)\n",
        "  X = layers.Dense(512, activation = 'relu' , name = 'fc512', kernel_initializer = glorot_uniform(seed=0) ) (X)\n",
        "  X = layers.Dense(1, activation = 'sigmoid' , name = 'fc' + str(classes), kernel_initializer = glorot_uniform(seed=0) ) (X)\n",
        "\n",
        "  model = keras.Model(inputs = X_INPUT, outputs = X, name = \"ResNet50\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yncQgd1LTGyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_size=(150,150,3),classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndTbMpQMTG1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s82bRZqoTG-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmOlE96OTHEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itpH2IzTHBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWpqh9lNTG7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tli1moQTG4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkmW9HpTGwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjnoyo-RTGqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se4PkgFXTFpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXlnXxXMQOLI",
        "colab_type": "text"
      },
      "source": [
        "![demo](https://drive.google.com/uc?export=view&id=1qlPeM2pXOJ-ItGGt6Cn6oHy1aEBDCEwK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWRkcK_DSUbv",
        "colab_type": "text"
      },
      "source": [
        "# Simple resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BQrav4anTmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_block(input_data,filters,conv_size):\n",
        "  x = layers.Conv2D(filters,conv_size,activation='relu',padding='same')(input_data)\n",
        "  x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  x = layers.Conv2D(filters,conv_size,activation=None,padding='same')(x)\n",
        "  x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  x = layers.Add()([x,input_data])\n",
        "  x = layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "# def ResNet(num_res_net_blocks ,input_size, filters, conv_size):\n",
        "#   inputs = layers.Input(shape=input_size)\n",
        "#   x = layers.Conv2D(32, (3,3),activation=None )(inputs)\n",
        "#   x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "#   x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
        "\n",
        "#   #for i in range(num_res_net_blocks):\n",
        "#   x = resnet_block(x,filters,conv_size)\n",
        "\n",
        "    \n",
        "#   x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "#   x = layers.MaxPooling2D()(x)\n",
        "\n",
        "#   x = layers.Flatten()(x)\n",
        "#   x = layers.Dense(256, activation='relu')(x)\n",
        "#   # x = layers.Dense(128, activation='relu')(x)\n",
        "#   # x = layers.Dropout(0.5)(x)\n",
        "#   outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "#   model = keras.Model(inputs,outputs)\n",
        "#   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKo2hGjtT8bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF9V-owPhS3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet(1,input_size=(150,150,3),filters=128,conv_size=(3,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVBnV--PfgFR",
        "colab_type": "text"
      },
      "source": [
        "#Simple RenNet Model (Functional API Model define)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjIPWYWPrrD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reglar_CNN_block(input_data,filters,conv_size,strides=(1, 1), kernel_initializer=glorot_uniform(seed=0), use_dropout=False, dropout=0.2):\n",
        "  x = layers.Conv2D(filters, conv_size,activation=None,strides=strides,kernel_initializer=kernel_initializer )(input_data)\n",
        "  x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  if use_dropout:\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAPuTd_2aH6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plain NN (Functional Model)\n",
        "def SimpleRes(input_size):\n",
        "  inputs = layers.Input(shape=input_size)\n",
        "  x = reglar_CNN_block(inputs,32,(3,3))\n",
        "  # x = reglar_CNN_block(x,32,(3,3))\n",
        "  x = reglar_CNN_block(x,64,(3,3))\n",
        "  x = reglar_CNN_block(x,128,(3,3))\n",
        "\n",
        "  # x = layers.Conv2D(16, (3,3),activation=None )(inputs)\n",
        "  # x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  # x = layers.Activation('relu')(x)\n",
        "  # x = layers.MaxPool2D()(x)\n",
        "  # x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x = layers.Conv2D(32, (3,3),activation=None )(x)\n",
        "  # x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  # x = layers.Activation('relu')(x)\n",
        "  # x = layers.MaxPool2D()(x)\n",
        "  # x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x = layers.Conv2D(64, (3,3),activation=None )(x)\n",
        "  # x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  # x = layers.Activation('relu')(x)\n",
        "  # x = layers.MaxPool2D()(x)\n",
        "  # x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x = layers.Conv2D(128, (3,3),activation=None )(x)\n",
        "  # x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  # x = layers.Activation('relu')(x)\n",
        "  # x = layers.MaxPool2D()(x)\n",
        "  # x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "\n",
        "\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  x = resnet_block(x,128,(3,3))\n",
        "  # x = layers.Conv2D(256, (3,3),activation=None )(x)\n",
        "  # x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  # x = layers.Activation('relu')(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(512, activation=None)(x)\n",
        "  x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.Dropout(0.4)(x)\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "  mod = keras.Model(inputs,outputs)\n",
        "  return mod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6LRlmMdbkb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = PlainNet((150,150,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK3Z1dZItQbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SimpleRes((150,150,3))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPsChc1HfR1g",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUfzE6zXwO2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WITH BatchNormalization (Sequential Model)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D( 16,(3,3),activation=None,input_shape=(150,150,3)),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D( 32,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D( 64,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(256,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512,activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "# YOUR CODE HERE\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mHUrRGRCrUi",
        "colab_type": "text"
      },
      "source": [
        "# Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvD8_W-vSFzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
        "model.compile(optimizer=Adam(lr=LR), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL8bcxAzfXPB",
        "colab_type": "text"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlNjoJ5D61N6",
        "colab_type": "code",
        "outputId": "b2401b4b-df60-47a6-8985-c68579e80221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        "    )\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,batch_size=64,target_size=targetSize,class_mode=\"binary\")\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_generator = train_datagen.flow_from_directory(VALIDATION_DIR,batch_size=64,target_size=targetSize,class_mode=\"binary\")\n",
        "\n",
        "\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22496 images belonging to 2 classes.\n",
            "Found 2502 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suwr7BpaYE9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh2XxnFDSZOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH7Ne8NhSZR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4SidOu22W9T",
        "colab_type": "text"
      },
      "source": [
        "# TensorBoard Launch\n",
        "\n",
        "[link](https://www.dlology.com/blog/how-to-run-tensorboard-in-jupyter-notebook/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV7SarrvSZVS",
        "colab_type": "code",
        "outputId": "aa9ac9b7-f4c9-44a8-952d-40ae913e4538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDfiIR8qSZFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = '/content/drive/My Drive/logs/cat_dog/'\n",
        "try:\n",
        "    # os.mkdir(LOG_DIR)\n",
        "    os.makedirs(LOG_DIR, exist_ok=True)\n",
        "except OSError:\n",
        "    print(\"Path Error\")\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fWMkvAdLyxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEST\n",
        "!cd /content/drive/\"My Drive\"/logs/cat_dog/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q07PxKyBjZGV",
        "colab_type": "code",
        "outputId": "50424117-db02-4b30-e28d-f185ea933890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72ioOa0JTUBE",
        "colab_type": "code",
        "outputId": "bc3531d8-0c38-4127-e111-7e36432f724c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# start hera\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH2DziudMuBT",
        "colab_type": "code",
        "outputId": "e60b5252-d19c-4937-ffe0-05088bef4ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# path with '' ---> (for rm & tb cmd)\n",
        "regDir = LOG_DIR.replace(\"My Drive\",\"'My Drive'\")\n",
        "regDir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40e147b5463e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLOG_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"My Drive\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"'My Drive'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregDir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LOG_DIR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFnprMA_SDEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DELETE ALL LOGS EXISTED!!!\n",
        "# !rm -rf {regDir}  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hf5v8CZK2JoQ",
        "colab": {}
      },
      "source": [
        "# logs_base_dir = \"/content/drive/Shared drives/Share/logs/cat_dog/\"\n",
        "# # os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "# # %tensorboard --logdir {logs_base_dir}\n",
        "%tensorboard --logdir  {regDir}\n",
        "# %tensorboard --logdir ./logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuiVQ_blTT4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# _logdir = os.path.join(LOG_DIR, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(_logdir, histogram_freq=1)    \n",
        "# print(_logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltRQHMClNRT9",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard display alternative way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUtN1cAIeu1O",
        "colab_type": "code",
        "outputId": "fe84ae72-67b5-4c19-8522-f213e01d4aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Known TensorBoard instances:\n",
            "  - port 6006: logdir /content/drive/My Drive/logs/cat_dog/ (started 0:00:35 ago; pid 420)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE_GekJA4BWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Control TensorBoard display. If no port is provided, \n",
        "# the most recently launched TensorBoard is used\n",
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8fFBvC2dw4",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks & Train\n",
        "\n",
        "[callbacks](https://keras.io/zh/callbacks/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBQ6zE29rCaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model_DIR = '/content/drive/My Drive/models/cat_dog/'\n",
        "os.makedirs(Model_DIR,exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSm8EiauekH5",
        "colab_type": "code",
        "outputId": "8f02a5e6-a06a-4e03-9c51-7f61a9575e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "# tensorboard_callback\n",
        "# log_dir=LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"-DOGCAT-\" + \"_lr-%.4f_decay-%.2f/\"%(LR,DECAY)\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "# print(log_dir)\n",
        " \n",
        "#filepath 可以包括命名格式选项，可以由 epoch 的值和 logs 的键（由 on_epoch_end 参数传递）来填充。\n",
        "#例如：如果 filepath 是 weights.{epoch:02d}-{val_loss:.2f}.hdf5， 那么模型被保存的的文件名就会有训练轮数和验证损失。\n",
        "\n",
        "#monitor: 被监测的数据。\n",
        "#verbose: 详细信息模式，0 或者 1 。\n",
        "#save_best_only: 如果 save_best_only=True， 被监测数据的最佳模型就不会被覆盖。\n",
        "#mode: {auto, min, max} 的其中之一。 如果 save_best_only=True，那么是否覆盖保存文件的决定就取决于被监测数据的最大或者最小值。 对于 val_acc，模式就会是 max，而对于 val_loss，模式就需要是 min，等等。 在 auto 模式中，方向会自动从被监测的数据的名字中判断出来。\n",
        "#save_weights_only: 如果 True，那么只有模型的权重会被保存 (model.save_weights(filepath))， 否则的话，整个模型会被保存 (model.save(filepath))。\n",
        "# keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "checkpoint = ModelCheckpoint(Model_DIR + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "                             monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=DECAY, patience=4, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyS4n53w7DxC",
        "colab_type": "code",
        "outputId": "96d60a54-bfb8-44e0-fd4b-2663fe141a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Remember to add callbacks here...\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=Epochs,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator, \n",
        "                              # callbacks=[tensorboard_callback,checkpoint,reduce_lr,early_stopping])\n",
        "                              callbacks=[WandbCallback(),checkpoint,reduce_lr,early_stopping])\n",
        "\n",
        "# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n",
        "# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 352 steps, validate for 40 steps\n",
            "Epoch 1/50\n",
            "352/352 [==============================] - 297s 843ms/step - loss: 1.0865 - acc: 0.5964 - val_loss: 0.7939 - val_acc: 0.5168\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 287s 816ms/step - loss: 0.6045 - acc: 0.6715 - val_loss: 0.6033 - val_acc: 0.6595\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 286s 813ms/step - loss: 0.5749 - acc: 0.6983 - val_loss: 0.5857 - val_acc: 0.6990\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 284s 806ms/step - loss: 0.5546 - acc: 0.7144 - val_loss: 0.5923 - val_acc: 0.6910\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 283s 804ms/step - loss: 0.5406 - acc: 0.7267 - val_loss: 0.7677 - val_acc: 0.5911\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 283s 804ms/step - loss: 0.5153 - acc: 0.7449 - val_loss: 1.2862 - val_acc: 0.5532\n",
            "Epoch 7/50\n",
            "351/352 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.7603\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.001200000010430813.\n",
            "352/352 [==============================] - 284s 807ms/step - loss: 0.4928 - acc: 0.7605 - val_loss: 0.8393 - val_acc: 0.5655\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 283s 805ms/step - loss: 0.4331 - acc: 0.8002 - val_loss: 0.6548 - val_acc: 0.6567\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 284s 805ms/step - loss: 0.4161 - acc: 0.8080 - val_loss: 0.9657 - val_acc: 0.6247\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 283s 805ms/step - loss: 0.4001 - acc: 0.8176 - val_loss: 0.6195 - val_acc: 0.6815\n",
            "Epoch 11/50\n",
            "351/352 [============================>.] - ETA: 0s - loss: 0.3883 - acc: 0.8222\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00048000002279877666.\n",
            "352/352 [==============================] - 282s 802ms/step - loss: 0.3882 - acc: 0.8223 - val_loss: 3.5132 - val_acc: 0.5416\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 284s 807ms/step - loss: 0.3461 - acc: 0.8464 - val_loss: 0.4405 - val_acc: 0.7970\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 285s 809ms/step - loss: 0.3269 - acc: 0.8558 - val_loss: 0.3649 - val_acc: 0.8333\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 284s 808ms/step - loss: 0.3192 - acc: 0.8589 - val_loss: 0.5492 - val_acc: 0.7494\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 283s 804ms/step - loss: 0.3098 - acc: 0.8632 - val_loss: 0.3657 - val_acc: 0.8301\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 284s 807ms/step - loss: 0.3051 - acc: 0.8653 - val_loss: 0.3872 - val_acc: 0.8149\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 285s 811ms/step - loss: 0.2988 - acc: 0.8666 - val_loss: 0.3516 - val_acc: 0.8409\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 283s 804ms/step - loss: 0.2866 - acc: 0.8772 - val_loss: 0.4905 - val_acc: 0.7994\n",
            "Epoch 19/50\n",
            " 30/352 [=>............................] - ETA: 3:56 - loss: 0.2713 - acc: 0.8804WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            " 30/352 [=>............................] - ETA: 4:00 - loss: 0.2713 - acc: 0.8804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-2dbe0ac4abf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0;31m# callbacks=[tensorboard_callback,checkpoint,reduce_lr,early_stopping])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               callbacks=[WandbCallback(),checkpoint,reduce_lr,early_stopping])\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2FosshNNmY0",
        "colab_type": "text"
      },
      "source": [
        "# Plot acc,loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZrJN4-65RC",
        "colab_type": "code",
        "outputId": "15c9ff2c-0ac0-4622-bc82-6c75b870468e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "# PLOT LOSS AND ACCURACY \n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEICAYAAAAqQj/TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAEICAYAAADocntXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbECsN7xyGR3",
        "colab_type": "text"
      },
      "source": [
        "#load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4BbGY3NyE3X",
        "colab_type": "code",
        "outputId": "b9fd180d-23ed-4e68-e360-794d61976404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 72, 72, 64)   9472        input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 72, 72, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 72, 72, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 35, 35, 64)   0           activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_2a_branch2a (Conv2D)   (None, 35, 35, 64)   4160        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "BN_2a_branch2a (BatchNormalizat (None, 35, 35, 64)   256         Res_Conv_2a_branch2a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 35, 35, 64)   0           BN_2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_2a_branch2b (Conv2D)   (None, 35, 35, 64)   36928       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_2a_branch2b (BatchNormalizat (None, 35, 35, 64)   256         Res_Conv_2a_branch2b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 35, 35, 64)   0           BN_2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_2a_branch2c (Conv2D)   (None, 35, 35, 256)  16640       activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_2a_branch_st (Conv2D)  (None, 35, 35, 256)  16640       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "BN_2a_branch2c (BatchNormalizat (None, 35, 35, 256)  1024        Res_Conv_2a_branch2c[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "BN_2a_branch_st (BatchNormaliza (None, 35, 35, 256)  1024        Res_Conv_2a_branch_st[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 35, 35, 256)  0           BN_2a_branch2c[0][0]             \n",
            "                                                                 BN_2a_branch_st[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 35, 35, 256)  0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_2_b2c (Conv2D)         (None, 35, 35, 256)  65792       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_2_b2c (BatchNormalizatio (None, 35, 35, 256)  1024        RES_CONV_2_b2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 35, 35, 256)  0           RES_BN_2_b2c[0][0]               \n",
            "                                                                 activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 35, 35, 256)  0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_2_c2c (Conv2D)         (None, 35, 35, 256)  65792       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_2_c2c (BatchNormalizatio (None, 35, 35, 256)  1024        RES_CONV_2_c2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 35, 35, 256)  0           RES_BN_2_c2c[0][0]               \n",
            "                                                                 activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 35, 35, 256)  0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_3a_branch2a (Conv2D)   (None, 18, 18, 128)  32896       activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_3a_branch2a (BatchNormalizat (None, 18, 18, 128)  512         Res_Conv_3a_branch2a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 18, 18, 128)  0           BN_3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_3a_branch2b (Conv2D)   (None, 18, 18, 128)  147584      activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_3a_branch2b (BatchNormalizat (None, 18, 18, 128)  512         Res_Conv_3a_branch2b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 18, 18, 128)  0           BN_3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_3a_branch2c (Conv2D)   (None, 18, 18, 512)  66048       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_3a_branch_st (Conv2D)  (None, 18, 18, 512)  131584      activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_3a_branch2c (BatchNormalizat (None, 18, 18, 512)  2048        Res_Conv_3a_branch2c[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "BN_3a_branch_st (BatchNormaliza (None, 18, 18, 512)  2048        Res_Conv_3a_branch_st[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 18, 18, 512)  0           BN_3a_branch2c[0][0]             \n",
            "                                                                 BN_3a_branch_st[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 18, 18, 512)  0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_3_b2c (Conv2D)         (None, 18, 18, 512)  262656      activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_3_b2c (BatchNormalizatio (None, 18, 18, 512)  2048        RES_CONV_3_b2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 18, 18, 512)  0           RES_BN_3_b2c[0][0]               \n",
            "                                                                 activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 18, 18, 512)  0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_3_c2c (Conv2D)         (None, 18, 18, 512)  262656      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_3_c2c (BatchNormalizatio (None, 18, 18, 512)  2048        RES_CONV_3_c2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 18, 18, 512)  0           RES_BN_3_c2c[0][0]               \n",
            "                                                                 activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 18, 18, 512)  0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_3_d2c (Conv2D)         (None, 18, 18, 512)  262656      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_3_d2c (BatchNormalizatio (None, 18, 18, 512)  2048        RES_CONV_3_d2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 18, 18, 512)  0           RES_BN_3_d2c[0][0]               \n",
            "                                                                 activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 18, 18, 512)  0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_4a_branch2a (Conv2D)   (None, 9, 9, 256)    131328      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_4a_branch2a (BatchNormalizat (None, 9, 9, 256)    1024        Res_Conv_4a_branch2a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 9, 9, 256)    0           BN_4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_4a_branch2b (Conv2D)   (None, 9, 9, 256)    590080      activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_4a_branch2b (BatchNormalizat (None, 9, 9, 256)    1024        Res_Conv_4a_branch2b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 9, 9, 256)    0           BN_4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_4a_branch2c (Conv2D)   (None, 9, 9, 1024)   263168      activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_4a_branch_st (Conv2D)  (None, 9, 9, 1024)   525312      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_4a_branch2c (BatchNormalizat (None, 9, 9, 1024)   4096        Res_Conv_4a_branch2c[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "BN_4a_branch_st (BatchNormaliza (None, 9, 9, 1024)   4096        Res_Conv_4a_branch_st[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 9, 9, 1024)   0           BN_4a_branch2c[0][0]             \n",
            "                                                                 BN_4a_branch_st[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 9, 9, 1024)   0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_4_b2c (Conv2D)         (None, 9, 9, 1024)   1049600     activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_4_b2c (BatchNormalizatio (None, 9, 9, 1024)   4096        RES_CONV_4_b2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 9, 9, 1024)   0           RES_BN_4_b2c[0][0]               \n",
            "                                                                 activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 9, 9, 1024)   0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_4_c2c (Conv2D)         (None, 9, 9, 1024)   1049600     activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_4_c2c (BatchNormalizatio (None, 9, 9, 1024)   4096        RES_CONV_4_c2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 9, 9, 1024)   0           RES_BN_4_c2c[0][0]               \n",
            "                                                                 activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 9, 9, 1024)   0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_4_d2c (Conv2D)         (None, 9, 9, 1024)   1049600     activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_4_d2c (BatchNormalizatio (None, 9, 9, 1024)   4096        RES_CONV_4_d2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 9, 9, 1024)   0           RES_BN_4_d2c[0][0]               \n",
            "                                                                 activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 9, 9, 1024)   0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_4_e2c (Conv2D)         (None, 9, 9, 1024)   1049600     activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_4_e2c (BatchNormalizatio (None, 9, 9, 1024)   4096        RES_CONV_4_e2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 9, 9, 1024)   0           RES_BN_4_e2c[0][0]               \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 9, 9, 1024)   0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_4_f2c (Conv2D)         (None, 9, 9, 1024)   1049600     activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_4_f2c (BatchNormalizatio (None, 9, 9, 1024)   4096        RES_CONV_4_f2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 9, 9, 1024)   0           RES_BN_4_f2c[0][0]               \n",
            "                                                                 activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 9, 9, 1024)   0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_5a_branch2a (Conv2D)   (None, 5, 5, 512)    524800      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_5a_branch2a (BatchNormalizat (None, 5, 5, 512)    2048        Res_Conv_5a_branch2a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 5, 5, 512)    0           BN_5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_5a_branch2b (Conv2D)   (None, 5, 5, 512)    2359808     activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_5a_branch2b (BatchNormalizat (None, 5, 5, 512)    2048        Res_Conv_5a_branch2b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 5, 5, 512)    0           BN_5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_5a_branch2c (Conv2D)   (None, 5, 5, 2048)   1050624     activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Res_Conv_5a_branch_st (Conv2D)  (None, 5, 5, 2048)   2099200     activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_5a_branch2c (BatchNormalizat (None, 5, 5, 2048)   8192        Res_Conv_5a_branch2c[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "BN_5a_branch_st (BatchNormaliza (None, 5, 5, 2048)   8192        Res_Conv_5a_branch_st[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 5, 5, 2048)   0           BN_5a_branch2c[0][0]             \n",
            "                                                                 BN_5a_branch_st[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 5, 5, 2048)   0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_5_b2c (Conv2D)         (None, 5, 5, 2048)   4196352     activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_5_b2c (BatchNormalizatio (None, 5, 5, 2048)   8192        RES_CONV_5_b2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 5, 5, 2048)   0           RES_BN_5_b2c[0][0]               \n",
            "                                                                 activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 5, 5, 2048)   0           add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "RES_CONV_5_c2c (Conv2D)         (None, 5, 5, 2048)   4196352     activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "RES_BN_5_c2c (BatchNormalizatio (None, 5, 5, 2048)   8192        RES_CONV_5_c2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 5, 5, 2048)   0           RES_BN_5_c2c[0][0]               \n",
            "                                                                 activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 5, 5, 2048)   0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pooling (AveragePooling2D)  (None, 2, 2, 2048)   0           activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8192)         0           avg_pooling[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 2)            16386       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,666,626\n",
            "Trainable params: 22,624,770\n",
            "Non-trainable params: 41,856\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed3ddXXJyOc1",
        "colab_type": "code",
        "outputId": "6ffc6dea-4a0c-44d5-f58c-7424f7d7134a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LOG_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/logs/cat_dog/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkHd-i8JyKSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(LOG_DIR + 'ep036-loss0.119-val_loss0.129.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS2UU1QtN2mP",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH4ljfPlGJl3",
        "colab_type": "text"
      },
      "source": [
        "## REMEMBER TO ADD (1/255) !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GUKKcMMGH5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqL6FYUrtXpf",
        "colab_type": "code",
        "outputId": "8ebb1158-4db2-4104-c797-33f17f372212",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  x = image.img_to_array(img) * (1/255)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-813222d1-f1c7-4dbb-95e7-7fc1e85889a4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-813222d1-f1c7-4dbb-95e7-7fc1e85889a4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cat1.jpg to cat1 (2).jpg\n",
            "Saving cat2.jpg to cat2 (1).jpg\n",
            "Saving cat3.jpg to cat3 (2).jpg\n",
            "Saving cat4.jpg to cat4 (4).jpg\n",
            "Saving cat5.jpg to cat5 (1).jpg\n",
            "Saving cat6.jpg to cat6 (3).jpg\n",
            "Saving cat7.jpg to cat7 (1).jpg\n",
            "Saving cat8.jpg to cat8 (1).jpg\n",
            "Saving dog1.jpg to dog1 (1).jpg\n",
            "Saving dog2.jpg to dog2 (1).jpg\n",
            "Saving dog3.jpg to dog3 (2).jpg\n",
            "Saving dog4.jpg to dog4 (2).jpg\n",
            "Saving dog5.jpg to dog5 (1).jpg\n",
            "Saving dog6.jpg to dog6 (1).jpg\n",
            "Saving dog7.jpg to dog7 (1).jpg\n",
            "Saving dog8.jpg to dog8 (1).jpg\n",
            "[[0.76533794]]\n",
            "[0.76533794]\n",
            "cat1.jpg is a dog\n",
            "[[0.19487248]]\n",
            "[0.19487248]\n",
            "cat2.jpg is a cat\n",
            "[[0.0174355]]\n",
            "[0.0174355]\n",
            "cat3.jpg is a cat\n",
            "[[0.00066156]]\n",
            "[0.00066156]\n",
            "cat4.jpg is a cat\n",
            "[[0.00593456]]\n",
            "[0.00593456]\n",
            "cat5.jpg is a cat\n",
            "[[0.02451831]]\n",
            "[0.02451831]\n",
            "cat6.jpg is a cat\n",
            "[[0.2138831]]\n",
            "[0.2138831]\n",
            "cat7.jpg is a cat\n",
            "[[0.4728716]]\n",
            "[0.4728716]\n",
            "cat8.jpg is a cat\n",
            "[[1.]]\n",
            "[1.]\n",
            "dog1.jpg is a dog\n",
            "[[0.9999894]]\n",
            "[0.9999894]\n",
            "dog2.jpg is a dog\n",
            "[[0.3093538]]\n",
            "[0.3093538]\n",
            "dog3.jpg is a cat\n",
            "[[0.99971265]]\n",
            "[0.99971265]\n",
            "dog4.jpg is a dog\n",
            "[[0.98296654]]\n",
            "[0.98296654]\n",
            "dog5.jpg is a dog\n",
            "[[0.9959864]]\n",
            "[0.9959864]\n",
            "dog6.jpg is a dog\n",
            "[[0.9803848]]\n",
            "[0.9803848]\n",
            "dog7.jpg is a dog\n",
            "[[0.9999565]]\n",
            "[0.9999565]\n",
            "dog8.jpg is a dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7iJAgiq7hwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UBZ81EC2GSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WITH BatchNormalization\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D( 16,(3,3),activation=None,input_shape=(300,300,3)),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D( 32,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D( 64,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(256,(3,3),activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512,activation=None),\n",
        "  tf.keras.layers.BatchNormalization(momentum=0.9),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  # tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "# YOUR CODE HERE\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVaJ67xf2H3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(LOG_DIR + 'ep036-loss0.119-val_loss0.129.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vggFyBwP9aEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(lr=LR), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fbg92M4Exs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}